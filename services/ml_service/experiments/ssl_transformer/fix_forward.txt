# ПРАВИЛЬНЫЙ forward для batched data (БЕЗ graph pooling)

def forward(self, x, edge_index=None, batch=None, return_embedding=False):
    """
    Forward pass for BATCHED tabular data (each sample is independent)
    
    Args:
        x: Features [batch_size, in_features]
        edge_index: Ignored for tabular data
        batch: Ignored for tabular data
        return_embedding: Return hidden representation
    
    Returns:
        [batch_size, num_classes] or [batch_size, hidden_dim]
    """
    batch_size = x.size(0)
    
    # Input projection
    h = self.input_proj(x)  # [batch_size, hidden_dim]
    h = F.relu(h)
    
    # For tabular data: treat each sample as a SINGLE-NODE graph
    # Create edges: self-loops only (or skip GAT entirely)
    
    # OPTION 1: Skip GAT layers for tabular data
    # Just use MLP
    h = self.dropout(h)
    
    # MLP layers (instead of GAT for tabular)
    for i in range(len(self.gat_layers)):
        # Use a simple MLP instead
        h = self.batch_norms[i](h)
        h = F.relu(h)
        h = self.dropout(h)
    
    if return_embedding:
        return h  # [batch_size, hidden_dim]
    
    # Classification
    out = self.classifier(h)  # [batch_size, num_classes]
    return out
