# ============================================================================
# ML Service with CUDA 12.4 GPU Support
# ============================================================================
FROM hydraulic-ai-base-gpu:cuda12.4

LABEL service="ml-inference"
LABEL gpu.required="true"

WORKDIR /app

# Copy ML-specific requirements
COPY requirements-ml.txt .

# Install ML-specific libraries (GPU versions)
RUN pip install --no-cache-dir -r requirements-ml.txt

# Copy ML service code
COPY . .

# Create directories
RUN mkdir -p /app/models /app/data

# GPU environment
ENV CUDA_VISIBLE_DEVICES=0 \
    NVIDIA_VISIBLE_DEVICES=all

# Healthcheck
HEALTHCHECK --interval=15s --timeout=5s --start-period=45s --retries=3 \
    CMD curl -f http://localhost:8001/health || exit 1

# Run
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8001", "--workers", "1"]
