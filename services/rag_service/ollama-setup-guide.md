# üöÄ RAG Service Quick Start —Å Ollama

## –®–∞–≥ 1: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Ollama

### Windows:
```bash
# –°–∫–∞—á–∞–π –∏ —É—Å—Ç–∞–Ω–æ–≤–∏ Ollama
# https://ollama.ai/download/windows

# –ò–ª–∏ —á–µ—Ä–µ–∑ winget
winget install Ollama.Ollama
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏:
```bash
ollama --version
```

---

## –®–∞–≥ 2: –ó–∞–ø—É—Å–∫ Ollama

```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç—å Ollama —Å–µ—Ä–≤–µ—Ä (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–µ)
ollama serve

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç
curl http://localhost:11434/api/tags
```

---

## –®–∞–≥ 3: –°–∫–∞—á–∞—Ç—å –º–æ–¥–µ–ª—å

```bash
# –õ–µ–≥–∫–∞—è –º–æ–¥–µ–ª—å –¥–ª—è CPU (1.5GB)
ollama pull deepseek-r1:1.5b

# –ò–ª–∏ –±–æ–ª–µ–µ –º–æ—â–Ω–∞—è –¥–ª—è GPU (7GB)
ollama pull deepseek-r1:7b

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
ollama list
```

---

## –®–∞–≥ 4: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Python –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
cd services/rag_service

# –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—ã–π requirements.txt
cp rag-requirements.txt requirements.txt

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install -r requirements.txt
```

---

## –®–∞–≥ 5: –û–±–Ω–æ–≤–∏—Ç—å –∫–æ–¥

### –ó–∞–º–µ–Ω–∏ `model_loader.py`:
```bash
# –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—ã–π —Ñ–∞–π–ª
cp model_loader_ollama.py model_loader.py
```

### –û–±–Ω–æ–≤–∏ `config.py`:
```python
class Settings(BaseSettings):
    # ... existing settings ...
    
    # Ollama settings
    OLLAMA_HOST: str = "http://localhost:11434"
    OLLAMA_MODEL: str = "deepseek-r1:1.5b"
    OLLAMA_TEMPERATURE: float = 0.7
    OLLAMA_MAX_TOKENS: int = 2048
```

---

## –®–∞–≥ 6: –ó–∞–ø—É—Å–∫ RAG Service

```bash
cd services/rag_service

# –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–µ—Ä–≤–∏—Å
python main.py
```

–û—Ç–∫—Ä–æ–µ—Ç—Å—è –Ω–∞ `http://localhost:8004`

---

## –®–∞–≥ 7: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```bash
# Health check
curl http://localhost:8004/health

# Test generation
curl -X POST http://localhost:8004/api/v1/interpret \
  -H "Content-Type: application/json" \
  -d '{
    "gnn_output": {
      "anomaly_detected": true,
      "confidence": 0.92,
      "component_id": "valve-1"
    },
    "query": "–ß—Ç–æ —Å–ª—É—á–∏–ª–æ—Å—å —Å –∫–ª–∞–ø–∞–Ω–æ–º?"
  }'
```

---

## üéØ –ú–æ–¥–µ–ª–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∑–∞–¥–∞—á:

### CPU-friendly (–ª–µ–≥–∫–∏–µ):
```bash
ollama pull deepseek-r1:1.5b      # 1.5GB - —Å–∞–º–∞—è –ª–µ–≥–∫–∞—è
ollama pull llama3.2:3b            # 3GB
ollama pull phi4:3.8b              # 3.8GB
```

### GPU (–º–æ—â–Ω—ã–µ):
```bash
ollama pull deepseek-r1:7b         # 7GB
ollama pull llama3.3:70b           # 70GB (—Ç—Ä–µ–±—É–µ—Ç –º–Ω–æ–≥–æ VRAM)
```

---

## üêõ Troubleshooting:

### Ollama –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è:
```bash
# –£–±–µ–¥–∏—Å—å, —á—Ç–æ –ø–æ—Ä—Ç 11434 —Å–≤–æ–±–æ–¥–µ–Ω
netstat -ano | findstr :11434

# –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏ Ollama
taskkill /F /IM ollama.exe
ollama serve
```

### –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è:
```bash
# –ü—Ä–æ–≤–µ—Ä—å –º–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ
dir C:\Users\%USERNAME%\.ollama\models

# –û—á–∏—Å—Ç–∏ —Å—Ç–∞—Ä—ã–µ –º–æ–¥–µ–ª–∏
ollama rm old-model-name
```

### –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ ollama:
```bash
pip install --upgrade ollama httpx
```

---

## ‚úÖ –ì–æ—Ç–æ–≤–æ!

RAG Service —Ç–µ–ø–µ—Ä—å —Ä–∞–±–æ—Ç–∞–µ—Ç —Å Ollama:
- ‚úÖ –õ–æ–∫–∞–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ –±–µ–∑ GPU
- ‚úÖ –ë—ã—Å—Ç—Ä–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
- ‚úÖ –ü–æ–ª–Ω–∞—è –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å
- ‚úÖ Production-ready

**–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥:** –ó–∞–ø—É—Å—Ç–∏ Frontend –∏ –ø—Ä–æ–≤–µ—Ä—å –ø–æ–ª–Ω—ã–π flow! üöÄ
