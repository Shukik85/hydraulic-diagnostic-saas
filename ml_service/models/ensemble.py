"""
Ensemble Model for Hydraulic Systems Anomaly Detection
Enterprise ensemble —Å CatBoost + XGBoost + RandomForest + Adaptive
Optimized with Fallback Strategies for <100ms p90 latency
"""

import asyncio
import time
from typing import Any

import numpy as np
import structlog

from config import MODEL_CONFIG, settings

from .adaptive_model import AdaptiveModel
from .base_model import BaseMLModel
from .catboost_model import CatBoostModel
from .random_forest_model import RandomForestModel
from .xgboost_model import XGBoostModel

logger = structlog.get_logger()


class EnsembleModel:
    """
    Enterprise Ensemble Model –¥–ª—è –≥–∏–¥—Ä–∞–≤–ª–∏—á–µ—Å–∫–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏.
    
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç 4 ML –º–æ–¥–µ–ª–∏ —Å progressive fallback strategies:
    - CatBoost (99.9% accuracy) - –≤–µ—Å 0.5 üéÜ –û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å
    - XGBoost (99.8% accuracy) - –≤–µ—Å 0.3
    - RandomForest (99.6% accuracy) - –≤–µ—Å 0.15
    - Adaptive (99.2% accuracy) - –≤–µ—Å 0.05 (–¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –ø–æ—Ä–æ–≥–∏)
    
    Fallback Strategies –¥–ª—è <100ms p90 latency:
    - Primary: CatBoost —Ç–æ–ª—å–∫–æ (15-30ms)
    - Secondary: CatBoost + XGBoost (25-50ms)
    - Tertiary: XGBoost + RandomForest (35-80ms)
    - Emergency: Adaptive —Ç–æ–ª—å–∫–æ (8-15ms)
    """

    def __init__(self):
        self.models: dict[str, BaseMLModel] = {}
        self.ensemble_weights = settings.ensemble_weights.copy()
        self.is_loaded = False
        self.load_start_time = None
        self.prediction_count = 0
        self.total_inference_time = 0.0

        # üöÄ Fallback –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è performance optimization
        self.fallback_strategies = {
            "primary": ["catboost"],                    # Fastest, highest accuracy
            "secondary": ["catboost", "xgboost"],       # Add secondary model
            "tertiary": ["xgboost", "random_forest"],   # Skip slowest models
            "emergency": ["adaptive"],                  # Minimal but working
        }
        
        # Performance tracking –¥–ª—è smart fallback
        self.model_performance = {
            "catboost": {"avg_time_ms": 15, "reliability": 0.99, "last_error": None},
            "xgboost": {"avg_time_ms": 25, "reliability": 0.97, "last_error": None},
            "random_forest": {"avg_time_ms": 45, "reliability": 0.95, "last_error": None},
            "adaptive": {"avg_time_ms": 8, "reliability": 0.92, "last_error": None},
        }

        # –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self.performance_metrics = {
            "predictions_total": 0,
            "inference_times": [],
            "accuracy_scores": [],
            "cache_hits": 0,
            "fallback_usage": {"primary": 0, "secondary": 0, "tertiary": 0, "emergency": 0},
        }

    async def load_models(self) -> None:
        """–û—Ç–ª–æ–∂–µ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π."""
        self.load_start_time = time.time()

        logger.info("Loading ensemble models", model_path=str(settings.model_path))

        try:
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π (‚úÖ –ë–µ–∑ HELM!)
            tasks = [
                self._load_catboost_model(),  # ‚úÖ –ù–æ–≤–∞—è –æ—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å
                self._load_xgboost_model(),
                self._load_random_forest_model(),
                self._load_adaptive_model(),
            ]

            results = await asyncio.gather(*tasks, return_exceptions=True)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    model_name = list(MODEL_CONFIG.keys())[i]
                    logger.error(f"Failed to load {model_name}", error=str(result))
                    # Update performance tracking
                    if model_name in self.model_performance:
                        self.model_performance[model_name]["last_error"] = str(result)
                        self.model_performance[model_name]["reliability"] *= 0.9  # Penalize

            loaded_models = [name for name, model in self.models.items() if model.is_loaded]

            if len(loaded_models) < 1:  # ‚úÖ Changed from 2 to 1 for emergency fallback
                raise RuntimeError(f"No models loaded: {loaded_models}")

            self.is_loaded = True
            load_time = time.time() - self.load_start_time

            logger.info(
                "Ensemble models loaded successfully",
                loaded_models=loaded_models,
                load_time_seconds=load_time,
                fallback_strategies=list(self.fallback_strategies.keys()),
            )

        except Exception as e:
            logger.error("Failed to load ensemble models", error=str(e))
            raise

    async def _load_catboost_model(self) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞ CatBoost –º–æ–¥–µ–ª–∏ (–æ—Å–Ω–æ–≤–Ω–∞—è)."""
        try:
            model = CatBoostModel()
            await model.load()
            self.models["catboost"] = model
        except Exception as e:
            logger.warning("CatBoost model failed to load", error=str(e))

    async def _load_xgboost_model(self) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞ XGBoost –º–æ–¥–µ–ª–∏."""
        try:
            model = XGBoostModel()
            await model.load()
            self.models["xgboost"] = model
        except Exception as e:
            logger.warning("XGBoost model failed to load", error=str(e))

    async def _load_random_forest_model(self) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞ RandomForest –º–æ–¥–µ–ª–∏."""
        try:
            model = RandomForestModel()
            await model.load()
            self.models["random_forest"] = model
        except Exception as e:
            logger.warning("RandomForest model failed to load", error=str(e))

    async def _load_adaptive_model(self) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞ Adaptive –º–æ–¥–µ–ª–∏."""
        try:
            model = AdaptiveModel()
            await model.load()
            self.models["adaptive"] = model
        except Exception as e:
            logger.warning("Adaptive model failed to load", error=str(e))

    async def predict(self, features: np.ndarray) -> dict[str, Any]:
        """
        üöÄ Enterprise ensemble –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å fallback strategies –¥–ª—è <100ms latency.

        Args:
            features: –ú–∞—Å—Å–∏–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º –∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        if not self.is_loaded:
            raise RuntimeError("Models not loaded")

        start_time = time.time()
        
        # üéØ Try fallback strategies –≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
        for strategy_name, model_names in self.fallback_strategies.items():
            try:
                available_models = [
                    (name, self.models[name]) 
                    for name in model_names 
                    if name in self.models and self.models[name].is_loaded
                ]
                
                if not available_models:
                    logger.debug(f"No models available for strategy {strategy_name}")
                    continue
                    
                logger.debug(f"Trying fallback strategy: {strategy_name}", 
                           models=[name for name, _ in available_models])
                
                # –í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –¥–æ—Å—Ç—É–ø–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
                result = await self._predict_with_models(
                    available_models, features, strategy_name
                )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                if self._is_prediction_acceptable(result, strategy_name):
                    # ‚úÖ Success - update metrics and return
                    inference_time = (time.time() - start_time) * 1000
                    
                    result["fallback_strategy"] = strategy_name
                    result["total_processing_time_ms"] = inference_time
                    
                    # Update performance metrics
                    self._update_metrics(inference_time, result["ensemble_score"])
                    self.performance_metrics["fallback_usage"][strategy_name] += 1
                    
                    # Performance monitoring
                    if inference_time > settings.max_inference_time_ms:
                        logger.warning(
                            "Inference time exceeded target",
                            inference_time_ms=inference_time,
                            target_ms=settings.max_inference_time_ms,
                            strategy=strategy_name,
                        )
                    
                    return result
                else:
                    logger.warning(f"Strategy {strategy_name} produced unacceptable prediction")
                    
            except Exception as e:
                logger.warning(f"Fallback strategy {strategy_name} failed", 
                              error=str(e))
                continue
        
        # üö® –ï—Å–ª–∏ –≤—Å–µ fallback —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø—Ä–æ–≤–∞–ª–∏–ª–∏—Å—å - critical error
        total_time = (time.time() - start_time) * 1000
        logger.error("All fallback strategies failed", 
                    processing_time_ms=total_time,
                    available_models=list(self.models.keys()))
        raise RuntimeError("All fallback strategies failed")

    async def _predict_with_models(
        self, 
        available_models: list[tuple[str, BaseMLModel]], 
        features: np.ndarray,
        strategy_name: str
    ) -> dict[str, Any]:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –Ω–∞–±–æ—Ä–æ–º –º–æ–¥–µ–ª–µ–π –∏ smart timeout."""
        
        # üéØ Smart timeout –Ω–∞ –æ—Å–Ω–æ–≤–µ strategy –¥–ª—è performance optimization
        timeouts = {
            "primary": 0.030,      # 30ms –¥–ª—è –±—ã—Å—Ç—Ä–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
            "secondary": 0.050,    # 50ms –¥–ª—è —Å—Ä–µ–¥–Ω–µ–π
            "tertiary": 0.080,     # 80ms –¥–ª—è –ø–æ–ª–Ω–æ–π
            "emergency": 0.015,    # 15ms –¥–ª—è –∞–≤–∞—Ä–∏–π–Ω–æ–π
        }
        
        timeout = timeouts.get(strategy_name, 0.100)
        
        # üöÄ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å graceful timeout handling
        tasks = []
        for model_name, model in available_models:
            task = asyncio.create_task(
                self._get_model_prediction_safe(model_name, model, features)
            )
            tasks.append((model_name, task))
        
        try:
            # ‚è±Ô∏è –ñ–¥–µ–º —Å timeout, –Ω–æ –ù–ï –ø—Ä–µ—Ä—ã–≤–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è graceful fallback
            done, pending = await asyncio.wait(
                [task for _, task in tasks],
                timeout=timeout,
                return_when=asyncio.ALL_COMPLETED
            )
            
            # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç –∑–∞–≤–µ—Ä—à–∏–≤—à–∏—Ö—Å—è –∑–∞–¥–∞—á
            individual_predictions = []
            for model_name, task in tasks:
                if task.done():
                    try:
                        result = await task
                        if "error" not in result:
                            individual_predictions.append(result)
                            # Update model performance tracking
                            self._update_model_performance(model_name, result)
                    except Exception as e:
                        logger.warning(f"Model {model_name} failed", error=str(e))
                        self._update_model_performance(model_name, None, str(e))
            
            # üîÑ –ï—Å–ª–∏ –µ—Å—Ç—å pending –∑–∞–¥–∞—á–∏ - –ø–æ–∑–≤–æ–ª—è–µ–º –∏–º –∑–∞–≤–µ—Ä—à–∏—Ç—å—Å—è –≤ —Ñ–æ–Ω–µ
            for task in pending:
                task.cancel()
            
            if not individual_predictions:
                raise RuntimeError(f"No valid predictions from strategy {strategy_name}")
            
            # –í—ã—á–∏—Å–ª—è–µ–º ensemble —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏
            return self._calculate_adaptive_ensemble_score(
                individual_predictions, strategy_name
            )
            
        except asyncio.TimeoutError:
            # üõ°Ô∏è Graceful fallback - –∏—Å–ø–æ–ª—å–∑—É–µ–º —á—Ç–æ —É—Å–ø–µ–ª–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å—Å—è
            logger.info(f"Strategy {strategy_name} timed out, using partial results")
            
            completed_predictions = []
            for model_name, task in tasks:
                if task.done() and not task.exception():
                    try:
                        result = await task
                        if "error" not in result:
                            completed_predictions.append(result)
                    except Exception:
                        continue
            
            if completed_predictions:
                return self._calculate_adaptive_ensemble_score(
                    completed_predictions, f"{strategy_name}_partial"
                )
            else:
                raise RuntimeError(f"Strategy {strategy_name} failed completely")

    async def _get_model_prediction_safe(
        self, model_name: str, model: BaseMLModel, features: np.ndarray
    ) -> dict[str, Any]:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å error handling."""
        start_time = time.time()
        
        try:
            prediction = await model.predict(features)
            processing_time = (time.time() - start_time) * 1000
            
            return {
                "model_name": model_name,
                "ml_model": model_name,  
                "model_version": model.version,
                "version": model.version,
                "prediction_score": prediction["score"],
                "confidence": prediction.get("confidence", 0.95),
                "processing_time_ms": processing_time,
                "features_used": len(features) if features.ndim == 1 else features.shape[1],
            }
        except Exception as e:
            processing_time = (time.time() - start_time) * 1000
            logger.warning(f"Model {model_name} prediction failed", 
                         error=str(e), processing_time_ms=processing_time)
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º error response –¥–ª—è graceful handling
            return {
                "model_name": model_name,
                "ml_model": model_name,
                "model_version": getattr(model, 'version', '1.0'),
                "version": getattr(model, 'version', '1.0'),
                "prediction_score": 0.5,  # Neutral score
                "confidence": 0.0,
                "processing_time_ms": processing_time,
                "features_used": 0,
                "error": str(e),
            }

    def _calculate_adaptive_ensemble_score(
        self, predictions: list[dict[str, Any]], strategy_name: str
    ) -> dict[str, Any]:
        """üéØ Adaptive ensemble scoring –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏."""
        
        if not predictions:
            return {"ensemble_score": 0.5, "severity": "normal", "confidence": 0.0, "is_anomaly": False}
        
        # üéØ –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –≤–µ—Å–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–ª—è optimal performance
        strategy_weights = {
            "primary": {"catboost": 1.0},
            "secondary": {"catboost": 0.7, "xgboost": 0.3},
            "tertiary": {"xgboost": 0.6, "random_forest": 0.4},
            "emergency": {"adaptive": 1.0},
        }
        
        weights = strategy_weights.get(
            strategy_name.replace("_partial", ""), 
            {}  # Fallback to equal weights
        )
        
        weighted_score = 0.0
        total_weight = 0.0
        confidence_sum = 0.0
        
        for pred in predictions:
            model_name = pred["model_name"]
            # üéØ Use strategy-specific weight or equal distribution
            weight = weights.get(model_name, 1.0 / len(predictions))
            
            weighted_score += pred["prediction_score"] * weight
            confidence_sum += pred["confidence"] * weight
            total_weight += weight
        
        if total_weight == 0:
            total_weight = 1.0
            
        final_score = weighted_score / total_weight
        final_confidence = confidence_sum / total_weight
        
        # Severity calculation
        if final_score < 0.3:
            severity = "normal"
        elif final_score < 0.6:
            severity = "warning"
        else:
            severity = "critical"
            
        return {
            "ensemble_score": final_score,
            "severity": severity,
            "is_anomaly": final_score > settings.prediction_threshold,
            "confidence": final_confidence,
            "models_used": len(predictions),
            "strategy_used": strategy_name,
            "individual_predictions": predictions,  # Include for API compatibility
        }

    def _is_prediction_acceptable(self, result: dict[str, Any], strategy: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è fallback decision."""
        
        # üéØ –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º
        min_confidence = {
            "primary": 0.95,
            "secondary": 0.90, 
            "tertiary": 0.85,
            "emergency": 0.80,
        }
        
        required_confidence = min_confidence.get(strategy, 0.80)
        
        return (
            result.get("confidence", 0) >= required_confidence and
            result.get("models_used", 0) > 0 and
            "ensemble_score" in result
        )
    
    def _update_model_performance(self, model_name: str, result: dict[str, Any] | None, error: str | None = None) -> None:
        """Update model performance tracking –¥–ª—è smart fallback decisions."""
        if model_name not in self.model_performance:
            return
            
        perf = self.model_performance[model_name]
        
        if error:
            perf["last_error"] = error
            perf["reliability"] = max(0.1, perf["reliability"] * 0.95)  # Penalize errors
        elif result:
            perf["last_error"] = None
            perf["reliability"] = min(0.99, perf["reliability"] * 1.01)  # Reward success
            
            # Update average processing time with exponential moving average
            if "processing_time_ms" in result:
                current_time = result["processing_time_ms"]
                perf["avg_time_ms"] = 0.8 * perf["avg_time_ms"] + 0.2 * current_time

    def _update_metrics(self, inference_time: float, accuracy: float) -> None:
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""
        self.performance_metrics["predictions_total"] += 1
        self.performance_metrics["inference_times"].append(inference_time)
        self.performance_metrics["accuracy_scores"].append(accuracy)

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —Å–ø–∏—Å–∫–æ–≤ (1000 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π)
        if len(self.performance_metrics["inference_times"]) > 1000:
            self.performance_metrics["inference_times"] = self.performance_metrics["inference_times"][-1000:]
            self.performance_metrics["accuracy_scores"] = self.performance_metrics["accuracy_scores"][-1000:]

    async def warmup(self, warmup_samples: int = 10) -> None:
        """üî• –ü—Ä–æ–≥—Ä–µ–≤ –º–æ–¥–µ–ª–µ–π –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–µ—Ä–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞."""
        logger.info("Warming up ensemble models with fallback strategies", samples=warmup_samples)

        # –°–∏–º—É–ª—è—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≥—Ä–µ–≤–∞
        dummy_features = np.random.rand(warmup_samples, 25)  # 25 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

        for i in range(warmup_samples):
            try:
                result = await self.predict(dummy_features[i])
                logger.debug(f"Warmup sample {i} completed", 
                           strategy=result.get("fallback_strategy", "unknown"),
                           time_ms=result.get("total_processing_time_ms", 0))
            except Exception as e:
                logger.warning(f"Warmup sample {i} failed", error=str(e))

        logger.info("Model warmup completed", 
                   fallback_usage=self.performance_metrics["fallback_usage"])

    def is_ready(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ ensemble —Å fallback support."""
        return self.is_loaded and len([m for m in self.models.values() if m.is_loaded]) >= 1  # ‚úÖ Relaxed requirement

    def get_loaded_models(self) -> list[str]:
        """–°–ø–∏—Å–æ–∫ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π."""
        return [name for name, model in self.models.items() if model.is_loaded]

    def get_model_info(self) -> dict[str, Any]:
        """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö —Å performance metrics."""
        model_info = {}

        for name, model in self.models.items():
            if model.is_loaded:
                perf = self.model_performance.get(name, {})
                model_info[name] = {
                    "name": MODEL_CONFIG[name]["name"],
                    "version": model.version,
                    "description": MODEL_CONFIG[name]["description"],
                    "accuracy_target": MODEL_CONFIG[name]["accuracy_target"],
                    "weight": MODEL_CONFIG[name]["weight"],
                    "is_loaded": True,
                    "avg_time_ms": perf.get("avg_time_ms", 0),
                    "reliability": perf.get("reliability", 1.0),
                    "last_error": perf.get("last_error"),
                }
            else:
                model_info[name] = {
                    "name": MODEL_CONFIG[name]["name"],
                    "is_loaded": False,
                    "error": "Failed to load",
                }

        return model_info

    def get_performance_metrics(self) -> dict[str, Any]:
        """üìà –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å fallback statistics."""
        if not self.performance_metrics["inference_times"]:
            return {"predictions_total": 0}

        times = self.performance_metrics["inference_times"]

        return {
            "predictions_total": self.performance_metrics["predictions_total"],
            "average_response_time_ms": np.mean(times),
            "p95_response_time_ms": np.percentile(times, 95),
            "p99_response_time_ms": np.percentile(times, 99),
            "min_response_time_ms": np.min(times),
            "max_response_time_ms": np.max(times),
            "average_accuracy": np.mean(self.performance_metrics["accuracy_scores"])
            if self.performance_metrics["accuracy_scores"]
            else 0.0,
            "fallback_usage": self.performance_metrics["fallback_usage"],
            "model_performance": self.model_performance,
        }

    async def cleanup(self) -> None:
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤."""
        logger.info("Cleaning up ensemble models")

        for model in self.models.values():
            try:
                await model.cleanup()
            except Exception as e:
                logger.warning("Model cleanup failed", error=str(e))

        self.models.clear()
        self.is_loaded = False