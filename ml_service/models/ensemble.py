"""
Ensemble Model for Hydraulic Systems Anomaly Detection  
Enterprise ensemble —Å CatBoost + XGBoost + RandomForest + Adaptive
"""

import asyncio
import time
from typing import Any

import numpy as np
import structlog

from config import MODEL_CONFIG, settings

from .adaptive_model import AdaptiveModel
from .base_model import BaseMLModel
from .catboost_model import CatBoostModel
from .random_forest_model import RandomForestModel
from .xgboost_model import XGBoostModel

logger = structlog.get_logger()


class EnsembleModel:
    """
    Enterprise Ensemble Model –¥–ª—è –≥–∏–¥—Ä–∞–≤–ª–∏—á–µ—Å–∫–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏.

    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç 4 ML –º–æ–¥–µ–ª–∏:
    - CatBoost (99.9% accuracy) - –≤–µ—Å 0.5 üéÜ –û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å
    - XGBoost (99.8% accuracy) - –≤–µ—Å 0.3
    - RandomForest (99.6% accuracy) - –≤–µ—Å 0.15
    - Adaptive (99.2% accuracy) - –≤–µ—Å 0.05 (–¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –ø–æ—Ä–æ–≥–∏)
    """

    def __init__(self):
        self.models: dict[str, BaseMLModel] = {}
        self.ensemble_weights = settings.ensemble_weights.copy()
        self.is_loaded = False
        self.load_start_time = None
        self.prediction_count = 0
        self.total_inference_time = 0.0

        # –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self.performance_metrics = {
            "predictions_total": 0,
            "inference_times": [],
            "accuracy_scores": [],
            "cache_hits": 0,
        }

    async def load_models(self) -> None:
        """–û—Ç–ª–æ–∂–µ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π."""
        self.load_start_time = time.time()

        logger.info("Loading ensemble models", model_path=settings.model_path)

        try:
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π (‚úÖ –ë–µ–∑ HELM!)
            tasks = [
                self._load_catboost_model(),  # ‚úÖ –ù–æ–≤–∞—è –æ—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å
                self._load_xgboost_model(),
                self._load_random_forest_model(),
                self._load_adaptive_model(),
            ]

            results = await asyncio.gather(*tasks, return_exceptions=True)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    model_name = list(MODEL_CONFIG.keys())[i]
                    logger.error(f"Failed to load {model_name}", error=str(result))

            loaded_models = [name for name, model in self.models.items() if model.is_loaded]

            if len(loaded_models) < 2:
                raise RuntimeError(f"Insufficient models loaded: {loaded_models}")

            self.is_loaded = True
            load_time = time.time() - self.load_start_time

            logger.info(
                "Ensemble models loaded successfully",
                loaded_models=loaded_models,
                load_time_seconds=load_time,
            )

        except Exception as e:
            logger.error("Failed to load ensemble models", error=str(e))
            raise

    async def _load_catboost_model(self) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞ CatBoost –º–æ–¥–µ–ª–∏ (–æ—Å–Ω–æ–≤–Ω–∞—è)."""
        try:
            model = CatBoostModel()
            await model.load()
            self.models["catboost"] = model
        except Exception as e:
            logger.warning("CatBoost model failed to load", error=str(e))

    async def _load_xgboost_model(self) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞ XGBoost –º–æ–¥–µ–ª–∏."""
        try:
            model = XGBoostModel()
            await model.load()
            self.models["xgboost"] = model
        except Exception as e:
            logger.warning("XGBoost model failed to load", error=str(e))

    async def _load_random_forest_model(self) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞ RandomForest –º–æ–¥–µ–ª–∏."""
        try:
            model = RandomForestModel()
            await model.load()
            self.models["random_forest"] = model
        except Exception as e:
            logger.warning("RandomForest model failed to load", error=str(e))

    async def _load_adaptive_model(self) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞ Adaptive –º–æ–¥–µ–ª–∏."""
        try:
            model = AdaptiveModel()
            await model.load()
            self.models["adaptive"] = model
        except Exception as e:
            logger.warning("Adaptive model failed to load", error=str(e))

    async def predict(self, features: np.ndarray) -> dict[str, Any]:
        """
        Enterprise ensemble –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å <20ms latency.

        Args:
            features: –ú–∞—Å—Å–∏–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º –∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        if not self.is_loaded:
            raise RuntimeError("Models not loaded")

        start_time = time.time()

        try:
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            prediction_tasks = []

            for model_name, model in self.models.items():
                if model.is_loaded:
                    task = self._get_model_prediction(model_name, model, features)
                    prediction_tasks.append(task)

            if not prediction_tasks:
                raise RuntimeError("No models available for prediction")

            # –û–∂–∏–¥–∞–Ω–∏–µ –≤—Å–µ—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            individual_predictions = await asyncio.gather(*prediction_tasks)

            # Ensemble –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ
            ensemble_result = self._calculate_ensemble_score(individual_predictions)

            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
            inference_time = (time.time() - start_time) * 1000  # –º—Å
            self._update_metrics(inference_time, ensemble_result["ensemble_score"])

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ latency requirement
            if inference_time > settings.max_inference_time_ms:
                logger.warning(
                    "Inference time exceeded target",
                    inference_time_ms=inference_time,
                    target_ms=settings.max_inference_time_ms,
                )

            return {
                **ensemble_result,
                "individual_predictions": individual_predictions,
                "total_processing_time_ms": inference_time,
                "cache_hit": False,  # TODO: –∏–º–ø–ª–µ–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ
            }

        except Exception as e:
            logger.error("Ensemble prediction failed", error=str(e))
            raise

    async def _get_model_prediction(self, model_name: str, model: BaseMLModel, features: np.ndarray) -> dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ—Ç –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏."""
        start_time = time.time()

        try:
            prediction = await model.predict(features)
            processing_time = (time.time() - start_time) * 1000

            # ‚úÖ Pydantic-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ –ø–æ–ª—è
            return {
                "model_name": model_name,
                "ml_model": model_name,
                "model_version": model.version,
                "version": model.version,
                "prediction_score": prediction["score"],
                "confidence": prediction.get("confidence", 0.95),
                "processing_time_ms": processing_time,
                "features_used": len(features) if features.ndim == 1 else features.shape[1],
            }

        except Exception as e:
            logger.error(f"Model {model_name} prediction failed", error=str(e))
            return {
                "model_name": model_name,
                "ml_model": model_name,
                "model_version": model.version,
                "version": model.version,
                "prediction_score": 0.5,  # –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π —Å–∫–æ—Ä
                "confidence": 0.0,
                "processing_time_ms": 0.0,
                "features_used": 0,
                "error": str(e),
            }

    def _calculate_ensemble_score(self, predictions: list[dict[str, Any]]) -> dict[str, Any]:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ ensemble —Å–∫–æ—Ä–∞ —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏."""
        if not predictions:
            return {"ensemble_score": 0.5, "severity": "normal", "confidence": 0.0, "is_anomaly": False}

        # –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤—ã–≤–∞–µ–º –æ—à–∏–±–æ—á–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        valid_predictions = [p for p in predictions if "error" not in p]

        if not valid_predictions:
            return {"ensemble_score": 0.5, "severity": "normal", "confidence": 0.0, "is_anomaly": False}

        # ‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ CatBoost ensemble
        weighted_score = 0.0
        total_weight = 0.0
        confidence_sum = 0.0

        model_weights = {
            "catboost": self.ensemble_weights[0],     # 50% - –û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å
            "xgboost": self.ensemble_weights[1],      # 30%
            "random_forest": self.ensemble_weights[2], # 15% 
            "adaptive": self.ensemble_weights[3],      # 5%
        }

        for pred in valid_predictions:
            model_name = pred["model_name"]
            weight = model_weights.get(model_name, 0.05)  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å

            weighted_score += pred["prediction_score"] * weight
            confidence_sum += pred["confidence"] * weight
            total_weight += weight

        if total_weight == 0:
            return {"ensemble_score": 0.5, "severity": "normal", "confidence": 0.0, "is_anomaly": False}

        final_score = weighted_score / total_weight
        final_confidence = confidence_sum / total_weight

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏
        if final_score < 0.3:
            severity = "normal"
        elif final_score < 0.6:
            severity = "warning"
        else:
            severity = "critical"

        return {
            "ensemble_score": final_score,
            "severity": severity,
            "is_anomaly": final_score > settings.prediction_threshold,
            "confidence": final_confidence,
        }

    def _update_metrics(self, inference_time: float, accuracy: float) -> None:
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""
        self.performance_metrics["predictions_total"] += 1
        self.performance_metrics["inference_times"].append(inference_time)
        self.performance_metrics["accuracy_scores"].append(accuracy)

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —Å–ø–∏—Å–∫–æ–≤ (1000 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π)
        if len(self.performance_metrics["inference_times"]) > 1000:
            self.performance_metrics["inference_times"] = self.performance_metrics["inference_times"][-1000:]
            self.performance_metrics["accuracy_scores"] = self.performance_metrics["accuracy_scores"][-1000:]

    async def warmup(self, warmup_samples: int = 10) -> None:
        """–ü—Ä–æ–≥—Ä–µ–≤ –º–æ–¥–µ–ª–µ–π –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–µ—Ä–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞."""
        logger.info("Warming up ensemble models", samples=warmup_samples)

        # –°–∏–º—É–ª—è—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≥—Ä–µ–≤–∞
        dummy_features = np.random.rand(warmup_samples, 25)  # 25 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

        for i in range(warmup_samples):
            try:
                await self.predict(dummy_features[i])
            except Exception as e:
                logger.warning(f"Warmup sample {i} failed", error=str(e))

        logger.info("Model warmup completed")

    def is_ready(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ ensemble."""
        return self.is_loaded and len([m for m in self.models.values() if m.is_loaded]) >= 2

    def get_loaded_models(self) -> list[str]:
        """–°–ø–∏—Å–æ–∫ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π."""
        return [name for name, model in self.models.items() if model.is_loaded]

    def get_model_info(self) -> dict[str, Any]:
        """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö."""
        model_info = {}

        for name, model in self.models.items():
            if model.is_loaded:
                model_info[name] = {
                    "name": MODEL_CONFIG[name]["name"],
                    "version": model.version,
                    "description": MODEL_CONFIG[name]["description"],
                    "accuracy_target": MODEL_CONFIG[name]["accuracy_target"],
                    "weight": MODEL_CONFIG[name]["weight"],
                    "is_loaded": True,
                }
            else:
                model_info[name] = {
                    "name": MODEL_CONFIG[name]["name"],
                    "is_loaded": False,
                    "error": "Failed to load",
                }

        return model_info

    def get_performance_metrics(self) -> dict[str, Any]:
        """–ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""
        if not self.performance_metrics["inference_times"]:
            return {"predictions_total": 0}

        times = self.performance_metrics["inference_times"]

        return {
            "predictions_total": self.performance_metrics["predictions_total"],
            "average_response_time_ms": np.mean(times),
            "p95_response_time_ms": np.percentile(times, 95),
            "p99_response_time_ms": np.percentile(times, 99),
            "min_response_time_ms": np.min(times),
            "max_response_time_ms": np.max(times),
            "average_accuracy": np.mean(self.performance_metrics["accuracy_scores"])
            if self.performance_metrics["accuracy_scores"]
            else 0.0,
        }

    async def cleanup(self) -> None:
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤."""
        logger.info("Cleaning up ensemble models")

        for model in self.models.values():
            try:
                await model.cleanup()
            except Exception as e:
                logger.warning("Model cleanup failed", error=str(e))

        self.models.clear()
        self.is_loaded = False
