# ML Inference Service Configuration
# Копировать в .env и настроить

# =============================================================================
# INTERNAL AUTHENTICATION (REQUIRED)
# =============================================================================
# Используется для backend→ml_service аутентификации
# Генерировать: python3 -c "import secrets; print(secrets.token_urlsafe(32))"
ML_INTERNAL_API_KEY=change-me-in-production-min-32-chars

# =============================================================================
# APPLICATION
# =============================================================================
DEBUG=false
ML_HOST=0.0.0.0
ML_PORT=8001
ML_WORKERS=4

# =============================================================================
# MODELS
# =============================================================================
MODEL_PATH=./models
PREDICTION_THRESHOLD=0.6
MAX_INFERENCE_TIME_MS=100
BATCH_SIZE=32

# =============================================================================
# PERFORMANCE
# =============================================================================
CACHE_PREDICTIONS=true
CACHE_TTL_SECONDS=300

# =============================================================================
# REDIS
# =============================================================================
REDIS_URL=redis://redis:6379/0
REDIS_MAX_CONNECTIONS=20

# =============================================================================
# DATABASE
# =============================================================================
DATABASE_URL=postgresql://hdx_user:hdx_password@db:5432/hydraulic_diagnostics

# =============================================================================
# MONITORING
# =============================================================================
ENABLE_METRICS=true
METRICS_PORT=9090
LOG_LEVEL=INFO

# =============================================================================
# HEALTH CHECKS
# =============================================================================
HEALTH_CHECK_INTERVAL=30
MODEL_WARMUP_TIMEOUT=60

# =============================================================================
# SECURITY (DEPRECATED - use ML_INTERNAL_API_KEY instead)
# =============================================================================
ML_API_KEY=  # deprecated, kept for backward compatibility
CORS_ORIGINS=http://localhost:3000,http://localhost:8000

# =============================================================================
# FEATURE ENGINEERING
# =============================================================================
FEATURE_WINDOW_MINUTES=10
SAMPLING_FREQUENCY_HZ=100.0

# =============================================================================
# ANOMALY DETECTION
# =============================================================================
ANOMALY_SENSITIVITY=0.8
MIN_DATA_POINTS=100

# =============================================================================
# EXTERNAL SERVICES
# =============================================================================
BACKEND_API_URL=http://backend:8000/api
NOTIFICATION_SERVICE_URL=

# =============================================================================
# NOTES:
# =============================================================================
# 1. ML_INTERNAL_API_KEY должен совпадать с backend .env
# 2. В production установите DEBUG=false
# 3. Используйте secrets management для ключей
# 4. ml_service НЕ должен быть доступен извне Docker network
